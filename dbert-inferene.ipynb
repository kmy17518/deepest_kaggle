{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Vanilla PyTorch BERT Starter - INFERENCE\n\nðŸ“Œ Here's the training notebook: https://www.kaggle.com/heyytanay/training-vanilla-pytorch-bert-starter\n\n**If you liked this notebook, you can leave an upvote :)**","metadata":{}},{"cell_type":"code","source":"import nltk\nimport platform\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport gc\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\n\nimport torch\nimport transformers\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import Dataset, DataLoader\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-09-16T17:00:49.983226Z","iopub.execute_input":"2022-09-16T17:00:49.983689Z","iopub.status.idle":"2022-09-16T17:00:49.990743Z","shell.execute_reply.started":"2022-09-16T17:00:49.983643Z","shell.execute_reply":"2022-09-16T17:00:49.989799Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Config:\n    MAX_LEN = 284\n    TRAIN_BS = 12\n    STATE_DIR = \"../input/state-list\"\n    MODEL_NAME = '../input/distilbertbaseuncased'\n    FILE_NAME = '../input/commonlitreadabilityprize/test.csv'\n    TOKENIZER = transformers.DistilBertTokenizer.from_pretrained('../input/distilbertbaseuncased', do_lower_case=True)\n    scaler = GradScaler()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T17:00:49.992277Z","iopub.execute_input":"2022-09-16T17:00:49.992956Z","iopub.status.idle":"2022-09-16T17:00:50.034999Z","shell.execute_reply.started":"2022-09-16T17:00:49.992809Z","shell.execute_reply":"2022-09-16T17:00:50.034216Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class BERTDataset(Dataset):\n    def __init__(self, review, target=None, is_test=False):\n        self.review = review\n        self.target = target\n        self.is_test = is_test\n        self.tokenizer = Config.TOKENIZER\n        self.max_len = Config.MAX_LEN\n    \n    def __len__(self):\n        return len(self.review)\n    \n    def __getitem__(self, idx):\n        review = str(self.review[idx])\n        review = ' '.join(review.split())\n        global inputs\n        \n        inputs = self.tokenizer.encode_plus(\n            review,\n            None,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True\n        )        \n        ids = torch.tensor(inputs['input_ids'], dtype=torch.long)\n        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n        \n        if self.is_test:\n            return {\n                'ids': ids,\n                'mask': mask,\n            }\n        else:    \n            targets = torch.tensor(self.target[idx], dtype=torch.float)\n            return {\n                'ids': ids,\n                'mask': mask,\n                'targets': targets\n            }","metadata":{"execution":{"iopub.status.busy":"2022-09-16T17:00:50.037012Z","iopub.execute_input":"2022-09-16T17:00:50.037363Z","iopub.status.idle":"2022-09-16T17:00:50.044830Z","shell.execute_reply.started":"2022-09-16T17:00:50.037327Z","shell.execute_reply":"2022-09-16T17:00:50.043879Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Model\nclass DBERT_BASE_UNCASED(nn.Module):\n    def __init__(self):\n        super(DBERT_BASE_UNCASED, self).__init__()\n        self.dbert = transformers.DistilBertModel.from_pretrained(Config.MODEL_NAME)\n        self.drop = nn.Dropout(0.2)\n        self.out = nn.Linear(768, 1)\n    \n    def forward(self, ids, mask):\n        output = self.dbert(ids, attention_mask=mask)\n        output = self.drop(output[0][:,0,:])\n        output = self.out(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-09-16T17:00:50.046386Z","iopub.execute_input":"2022-09-16T17:00:50.046744Z","iopub.status.idle":"2022-09-16T17:00:50.057618Z","shell.execute_reply.started":"2022-09-16T17:00:50.046708Z","shell.execute_reply":"2022-09-16T17:00:50.056858Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef inference(model, states_list, test_dataloader, device=torch.device('cuda:0')):\n    \"\"\"\n    Do inference for different model folds\n    \"\"\"\n    model.eval()\n    all_preds = []\n    for state in states_list:\n        print(f\"State: {state}\")\n        state_dict = torch.load(state)\n        model.load_state_dict(state_dict)\n        model = model.to(device)\n        \n        # Clean\n        del state_dict\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        preds = []\n        prog = tqdm(test_dataloader, total=len(test_dataloader))\n        for data in prog:\n            ids = data['ids'].to(DEVICE, dtype=torch.long)\n            mask = data['mask'].to(DEVICE, dtype=torch.long)\n\n            outputs = model(ids=ids, mask=mask)\n            preds.append(outputs.squeeze(-1).cpu().detach().numpy())\n            \n        all_preds.append(np.concatenate(preds))\n        \n        # Clean\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n    return all_preds","metadata":{"execution":{"iopub.status.busy":"2022-09-16T17:00:50.058850Z","iopub.execute_input":"2022-09-16T17:00:50.059193Z","iopub.status.idle":"2022-09-16T17:00:50.069431Z","shell.execute_reply.started":"2022-09-16T17:00:50.059158Z","shell.execute_reply":"2022-09-16T17:00:50.068754Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Inference Code\nif __name__ == '__main__':\n    if torch.cuda.is_available():\n        print(\"\\n[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n        DEVICE = torch.device('cuda:0')\n    else:\n        print(\"\\n[INFO] GPU not found. Using CPU: {}\\n\".format(platform.processor()))\n        DEVICE = torch.device('cpu')\n    \n    test_file = pd.read_csv(Config.FILE_NAME)\n    \n    test_data = BERTDataset(test_file['excerpt'].values, is_test=True)\n    test_data = DataLoader(\n        test_data,\n        batch_size=Config.TRAIN_BS,\n        shuffle=False\n    )\n    \n    state_list = [os.path.join(Config.STATE_DIR, x) for x in os.listdir(Config.STATE_DIR) if x.endswith(\".pt\")]\n    model = DBERT_BASE_UNCASED()\n    \n    print(\"Doing Predictions for all folds\")\n    predictions = inference(model, state_list, test_data, device=DEVICE)\n    \n    final_predictions = pd.DataFrame(predictions).T.mean(axis=1).tolist()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T17:00:50.070873Z","iopub.execute_input":"2022-09-16T17:00:50.071284Z","iopub.status.idle":"2022-09-16T17:01:13.624942Z","shell.execute_reply.started":"2022-09-16T17:00:50.071248Z","shell.execute_reply":"2022-09-16T17:01:13.624063Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\n[INFO] Using GPU: Tesla P100-PCIE-16GB\n\nDoing Predictions for all folds\nState: ../input/state-list/distilbert-base-uncased_fold_3.pt\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"State: ../input/state-list/distilbert-base-uncased_fold_1.pt\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"State: ../input/state-list/distilbert-base-uncased_fold_2.pt\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"State: ../input/state-list/distilbert-base-uncased_fold_4.pt\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"State: ../input/state-list/distilbert-base-uncased_fold_0.pt\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.49it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Form the sample submission\nsub = pd.DataFrame()\nsub['id'] = test_file['id']\nsub['target'] = final_predictions\n\nsub.to_csv(\"submission.csv\", index=None)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T17:01:13.626370Z","iopub.execute_input":"2022-09-16T17:01:13.626927Z","iopub.status.idle":"2022-09-16T17:01:13.871944Z","shell.execute_reply.started":"2022-09-16T17:01:13.626887Z","shell.execute_reply":"2022-09-16T17:01:13.871177Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"          id    target\n0  c0f722661 -0.492420\n1  f0953f0a5  0.066403\n2  0df072751 -0.220630\n3  04caf4e0c -1.573857\n4  0e63f8bea -1.410894","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>c0f722661</td>\n      <td>-0.492420</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f0953f0a5</td>\n      <td>0.066403</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0df072751</td>\n      <td>-0.220630</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>04caf4e0c</td>\n      <td>-1.573857</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0e63f8bea</td>\n      <td>-1.410894</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}