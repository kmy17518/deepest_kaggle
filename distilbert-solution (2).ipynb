{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PyTorch BERT Multi-Model Trainer + KFoldsðŸŽ¯\n\nðŸ“Œ KFolds Inference (Submission) Notebook : https://www.kaggle.com/heyytanay/inference-0-6-lb-vanilla-pytorch-bert-starter\n\nðŸ“Œ My EDA and Multi Linear Models Notebook: https://www.kaggle.com/heyytanay/commonlit-readability-eda-multi-models","metadata":{}},{"cell_type":"code","source":"!pip install transformers==2.5.1","metadata":{"execution":{"iopub.status.busy":"2022-09-16T11:19:56.961748Z","iopub.execute_input":"2022-09-16T11:19:56.962062Z","iopub.status.idle":"2022-09-16T11:20:06.604682Z","shell.execute_reply.started":"2022-09-16T11:19:56.961989Z","shell.execute_reply":"2022-09-16T11:20:06.603715Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting transformers==2.5.1\n  Downloading transformers-2.5.1-py3-none-any.whl (499 kB)\n\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 499 kB 4.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==2.5.1) (1.19.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==2.5.1) (4.59.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==2.5.1) (2.25.1)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers==2.5.1) (0.1.95)\nCollecting tokenizers==0.5.2\n  Downloading tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.6 MB 22.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==2.5.1) (3.0.12)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==2.5.1) (0.0.45)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from transformers==2.5.1) (1.17.53)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==2.5.1) (2021.3.17)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->transformers==2.5.1) (0.10.0)\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->transformers==2.5.1) (0.3.7)\nRequirement already satisfied: botocore<1.21.0,>=1.20.53 in /opt/conda/lib/python3.7/site-packages (from boto3->transformers==2.5.1) (1.20.53)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.21.0,>=1.20.53->boto3->transformers==2.5.1) (2.8.1)\nRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.21.0,>=1.20.53->boto3->transformers==2.5.1) (1.26.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.53->boto3->transformers==2.5.1) (1.15.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==2.5.1) (2020.12.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==2.5.1) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==2.5.1) (2.10)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1) (1.0.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==2.5.1) (7.1.2)\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.10.2\n    Uninstalling tokenizers-0.10.2:\n      Successfully uninstalled tokenizers-0.10.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.5.1\n    Uninstalling transformers-4.5.1:\n      Successfully uninstalled transformers-4.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.3.0 requires transformers<4.6,>=4.1, but you have transformers 2.5.1 which is incompatible.\u001b[0m\nSuccessfully installed tokenizers-0.5.2 transformers-2.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport platform\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport gc\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch\nimport transformers\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import Dataset, DataLoader\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-09-16T11:20:06.606628Z","iopub.execute_input":"2022-09-16T11:20:06.606983Z","iopub.status.idle":"2022-09-16T11:20:13.521862Z","shell.execute_reply.started":"2022-09-16T11:20:06.606935Z","shell.execute_reply":"2022-09-16T11:20:13.521008Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Config:\n    NB_EPOCHS = 10\n    LR = 1e-6\n    MAX_LEN = 185\n    N_SPLITS = 5\n    TRAIN_BS = 16\n    VALID_BS = 32\n    MODEL_NAME = 'distilbert-base-uncased'\n    FILE_NAME = '../input/commonlitreadabilityprize/train.csv'\n    TOKENIZER = transformers.DistilBertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True)\n    scaler = GradScaler()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T11:20:13.524577Z","iopub.execute_input":"2022-09-16T11:20:13.525135Z","iopub.status.idle":"2022-09-16T11:20:13.969090Z","shell.execute_reply.started":"2022-09-16T11:20:13.525098Z","shell.execute_reply":"2022-09-16T11:20:13.968241Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5c5fccd499d4e9e8bdbf25d33d1a5ac"}},"metadata":{}}]},{"cell_type":"code","source":"class BERTDataset(Dataset):\n    def __init__(self, review, target=None, is_test=False):\n        self.review = review\n        self.target = target\n        self.is_test = is_test\n        self.tokenizer = Config.TOKENIZER\n        self.max_len = Config.MAX_LEN\n    \n    def __len__(self):\n        return len(self.review)\n    \n    def __getitem__(self, idx):\n        review = str(self.review[idx])\n        review = ' '.join(review.split())\n        global inputs\n        \n        inputs = self.tokenizer.encode_plus(\n            review,\n            None,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True\n        )        \n        ids = torch.tensor(inputs['input_ids'], dtype=torch.long)\n        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n        \n        if self.is_test:\n            return {\n                'ids': ids,\n                'mask': mask,\n            }\n        else:    \n            targets = torch.tensor(self.target[idx], dtype=torch.float)\n            return {\n                'ids': ids,\n                'mask': mask,\n                'targets': targets\n            }","metadata":{"execution":{"iopub.status.busy":"2022-09-16T11:20:13.971485Z","iopub.execute_input":"2022-09-16T11:20:13.972027Z","iopub.status.idle":"2022-09-16T11:20:13.980110Z","shell.execute_reply.started":"2022-09-16T11:20:13.971973Z","shell.execute_reply":"2022-09-16T11:20:13.979200Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    def __init__(\n        self, \n        model, \n        optimizer, \n        scheduler, \n        train_dataloader, \n        valid_dataloader,\n        device\n    ):\n        self.model = model\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.train_data = train_dataloader\n        self.valid_data = valid_dataloader\n        self.loss_fn = self.yield_loss\n        self.device = device\n        \n    def yield_loss(self, outputs, targets):\n        \"\"\"\n        This is the loss function for this task\n        \"\"\"\n        return torch.sqrt(nn.MSELoss()(outputs, targets))\n    \n    def train_one_epoch(self):\n        \"\"\"\n        This function trains the model for 1 epoch through all batches\n        \"\"\"\n        prog_bar = tqdm(enumerate(self.train_data), total=len(self.train_data))\n        self.model.train()\n        all_losses = []\n        with autocast():\n            for idx, inputs in prog_bar:\n                ids = inputs['ids'].to(self.device, dtype=torch.long)\n                mask = inputs['mask'].to(self.device, dtype=torch.long)\n                targets = inputs['targets'].to(self.device, dtype=torch.float)\n\n                outputs = self.model(ids=ids, mask=mask).view(-1)\n\n                loss = self.loss_fn(outputs, targets)\n                prog_bar.set_description('loss: {:.2f}'.format(loss.item()))\n                all_losses.append(loss.item())\n\n                Config.scaler.scale(loss).backward()\n                Config.scaler.step(self.optimizer)\n                Config.scaler.update()\n                self.optimizer.zero_grad()\n                self.scheduler.step()\n        \n        train_loss = sum(all_losses) / len(all_losses)\n        return train_loss\n        \n    \n    def valid_one_epoch(self):\n        \"\"\"\n        This function validates the model for one epoch through all batches of the valid dataset\n        It also returns the validation Root mean squared error for assesing model performance.\n        \"\"\"\n        prog_bar = tqdm(enumerate(self.valid_data), total=len(self.valid_data))\n        self.model.eval()\n        all_targets = []\n        all_predictions = []\n        with torch.no_grad():\n            for idx, inputs in prog_bar:\n                ids = inputs['ids'].to(self.device, dtype=torch.long)\n                mask = inputs['mask'].to(self.device, dtype=torch.long)\n                targets = inputs['targets'].to(self.device, dtype=torch.float)\n\n                outputs = self.model(ids=ids, mask=mask).view(-1)\n                all_targets.extend(targets.cpu().detach().numpy().tolist())\n                all_predictions.extend(outputs.cpu().detach().numpy().tolist())\n\n        val_rmse_loss = np.sqrt(mean_squared_error(all_targets, all_predictions))\n        print('Validation RMSE: {:.2f}'.format(val_rmse_loss))\n        \n        return val_rmse_loss\n    \n    def get_model(self):\n        return self.model","metadata":{"execution":{"iopub.status.busy":"2022-09-16T11:20:13.981487Z","iopub.execute_input":"2022-09-16T11:20:13.981889Z","iopub.status.idle":"2022-09-16T11:20:13.998654Z","shell.execute_reply.started":"2022-09-16T11:20:13.981855Z","shell.execute_reply":"2022-09-16T11:20:13.997884Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Model\nclass DBERT_BASE_UNCASED(nn.Module):\n    def __init__(self):\n        super(DBERT_BASE_UNCASED, self).__init__()\n        self.dbert = transformers.DistilBertModel.from_pretrained(Config.MODEL_NAME)\n        self.drop = nn.Dropout(0.2)\n        self.out = nn.Linear(768, 1)\n    \n    def forward(self, ids, mask):\n        output = self.dbert(ids, attention_mask=mask)\n        output = self.drop(output[0][:,0,:])\n        output = self.out(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-09-16T11:20:13.999913Z","iopub.execute_input":"2022-09-16T11:20:14.000457Z","iopub.status.idle":"2022-09-16T11:20:14.007965Z","shell.execute_reply.started":"2022-09-16T11:20:14.000422Z","shell.execute_reply":"2022-09-16T11:20:14.007228Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def yield_optimizer(model):\n    \"\"\"\n    Returns optimizer for specific parameters\n    \"\"\"\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {\n            \"params\": [\n                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n            ],\n            \"weight_decay\": 0.003,\n        },\n        {\n            \"params\": [\n                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n            ],\n            \"weight_decay\": 0.0,\n        },\n    ]\n    return transformers.AdamW(optimizer_parameters, lr=Config.LR)","metadata":{"execution":{"iopub.status.busy":"2022-09-16T11:20:14.009077Z","iopub.execute_input":"2022-09-16T11:20:14.009645Z","iopub.status.idle":"2022-09-16T11:20:14.017042Z","shell.execute_reply.started":"2022-09-16T11:20:14.009607Z","shell.execute_reply":"2022-09-16T11:20:14.016369Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Training Code\nif __name__ == '__main__':\n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n        DEVICE = torch.device('cuda:0')\n    else:\n        print(\"\\n[INFO] GPU not found. Using CPU: {}\\n\".format(platform.processor()))\n        DEVICE = torch.device('cpu')\n        \n    os.makedirs(\"./states_list\", exist_ok=True)\n    \n    data = pd.read_csv(Config.FILE_NAME)\n    data = data.sample(frac=1).reset_index(drop=True)\n    data = data[['excerpt', 'target']]\n    \n    # Do Kfolds training and cross validation\n    kf = StratifiedKFold(n_splits=Config.N_SPLITS)\n    nb_bins = int(np.floor(1 + np.log2(len(data))))\n    data.loc[:, 'bins'] = pd.cut(data['target'], bins=nb_bins, labels=False)\n    \n    train_losses = [{} for _ in range(Config.N_SPLITS)]\n    val_losses = [{} for _ in range(Config.N_SPLITS)]\n    \n    \n    for fold, (train_idx, valid_idx) in enumerate(kf.split(X=data, y=data['bins'].values)):\n        print(f\"\\nFold: {fold}\")\n        print(f\"{'-'*20}\\n\")\n        \n        train_data = data.loc[train_idx]\n        valid_data = data.loc[valid_idx]\n        \n        train_set = BERTDataset(\n            review = train_data['excerpt'].values,\n            target = train_data['target'].values\n        )\n\n        valid_set = BERTDataset(\n            review = valid_data['excerpt'].values,\n            target = valid_data['target'].values\n        )\n\n        train = DataLoader(\n            train_set,\n            batch_size = Config.TRAIN_BS,\n            shuffle = True,\n            num_workers=8\n        )\n\n        valid = DataLoader(\n            valid_set,\n            batch_size = Config.VALID_BS,\n            shuffle = False,\n            num_workers=8\n        )\n\n        model = DBERT_BASE_UNCASED().to(DEVICE)\n        nb_train_steps = int(len(train_data) / Config.TRAIN_BS * Config.NB_EPOCHS)\n        optimizer = yield_optimizer(model)\n        scheduler = transformers.get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=0,\n            num_training_steps=nb_train_steps\n        )\n\n        trainer = Trainer(model, optimizer, scheduler, train, valid, DEVICE)\n\n        best_loss = 100\n        for epoch in range(1, Config.NB_EPOCHS+1):\n            print(f\"\\n{'--'*5} EPOCH: {epoch} {'--'*5}\\n\")\n\n            # Train for 1 epoch\n            train_loss = trainer.train_one_epoch()\n            train_losses[fold][epoch] = train_loss\n\n            # Validate for 1 epoch\n            current_loss = trainer.valid_one_epoch()\n            val_losses[fold][epoch] = current_loss\n\n            if current_loss < best_loss:\n                print(f\"Saving best model in this fold: {current_loss:.4f}\")\n                torch.save(trainer.get_model().state_dict(), f\"./states_list/{Config.MODEL_NAME}_fold_{fold}.pt\")\n                best_loss = current_loss\n        \n        print(f\"Best RMSE in fold: {fold} was: {best_loss:.4f}\")\n        print(f\"Final RMSE in fold: {fold} was: {current_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-16T11:23:43.134751Z","iopub.execute_input":"2022-09-16T11:23:43.135101Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"[INFO] Using GPU: Tesla P100-PCIE-16GB\n\n\nFold: 0\n--------------------\n\n\n---------- EPOCH: 1 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7399fda28caa45cfbf841d1e5716d5c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6064f88f8de34a1187e843b25a23d33f"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.95\nSaving best model in this fold: 0.9514\n\n---------- EPOCH: 2 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"132ef7168b3047c2aef6c4bfef465e61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2513873a43f449efb752184eed49fef6"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.79\nSaving best model in this fold: 0.7945\n\n---------- EPOCH: 3 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c850f73a600f412c9fcdb650641a5aff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a70884afb4e34240b2d471c60a6b448b"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.70\nSaving best model in this fold: 0.7020\n\n---------- EPOCH: 4 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"916618adc8ad4341a68cc16f952b8ad2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0863d7ed15f4da0a5e8f9f7dba9f4b8"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.67\nSaving best model in this fold: 0.6699\n\n---------- EPOCH: 5 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c68759b01f934886839cd954100ed619"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96fbeffdfaa74789972e907cdd744775"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.65\nSaving best model in this fold: 0.6533\n\n---------- EPOCH: 6 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dad2cb46ad284a44bd4b4f08e8c0dae8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b6ad75c65d44979bbade040a3474870"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.65\nSaving best model in this fold: 0.6507\n\n---------- EPOCH: 7 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ada160f991441af8e0d0aa6ecf1017a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32383efb9d644a67adc3534c39fa8dfa"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.64\nSaving best model in this fold: 0.6434\n\n---------- EPOCH: 8 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79822f0d5d1244c8a00046832f1717a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"661f17020b3542c29a1e93d4264ad0fa"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.63\nSaving best model in this fold: 0.6334\n\n---------- EPOCH: 9 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"081ef221d3014659807a082cdd08a930"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcb938979b5845ef890fc20e6aa38b5d"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.63\nSaving best model in this fold: 0.6284\n\n---------- EPOCH: 10 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6895ebc9d15149ccb1d93dbe449b75f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21b236fc8bd0414191ad77f585f32349"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.63\nSaving best model in this fold: 0.6277\nBest RMSE in fold: 0 was: 0.6277\nFinal RMSE in fold: 0 was: 0.6277\n\nFold: 1\n--------------------\n\n\n---------- EPOCH: 1 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4063ef89db524d58a46f5e4986c312f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c54503476a84cea87cc5a12a0d4df7e"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.88\nSaving best model in this fold: 0.8839\n\n---------- EPOCH: 2 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8356fcc219c043609057130bfa3c9728"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef4c7def768340aa80b7c15e9ddf071a"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.72\nSaving best model in this fold: 0.7213\n\n---------- EPOCH: 3 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e75786c481b14859ba5828b8c59e2dfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e6ce3a404a74e1c93aaf95a821e747e"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.67\nSaving best model in this fold: 0.6715\n\n---------- EPOCH: 4 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0e4f9ab835945d49f695df3b6a78678"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eed2f8a817634e8c94419066327fb1dd"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.67\nSaving best model in this fold: 0.6677\n\n---------- EPOCH: 5 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67776086e3834088807e64c7169e3d9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b75c9f0afed5410eae9e7aa160c78590"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.65\nSaving best model in this fold: 0.6534\n\n---------- EPOCH: 6 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"089fa982e78c445d9deef5bd6503ef7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a50715dadb749b7b26847cbbee0c274"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.65\nSaving best model in this fold: 0.6460\n\n---------- EPOCH: 7 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"504ac61fdadc4ed8b502a0776b90c2fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a30c22a3edc644bc9699e3146f31842c"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.65\n\n---------- EPOCH: 8 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"201825c55f41414e9191150a90f825ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ac985f1dc2c45d9951878a740c0417b"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.64\nSaving best model in this fold: 0.6397\n\n---------- EPOCH: 9 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33e7f30ca666485abe232550a2450750"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e79e1a67cfb143fab402519e949e733d"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.64\nSaving best model in this fold: 0.6364\n\n---------- EPOCH: 10 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2fc545c922644e68e1e4a01315d161a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ce38f45d5aa4c528e5177926f4ef43e"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.64\nSaving best model in this fold: 0.6359\nBest RMSE in fold: 1 was: 0.6359\nFinal RMSE in fold: 1 was: 0.6359\n\nFold: 2\n--------------------\n\n\n---------- EPOCH: 1 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26f8b235ac214a8c8d5cb74a69f972b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be426083fed4f3fb1ed2cca2008ff60"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 1.00\nSaving best model in this fold: 1.0012\n\n---------- EPOCH: 2 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c97ad868609748b5b3cf6f357270f4cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c72114fc6c5b487ba233aae987e2f02d"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.84\nSaving best model in this fold: 0.8389\n\n---------- EPOCH: 3 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5371c2034d8149778c2beb5dc485fc76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a2c7bd3b21e46c7a938ebbf37fe8e44"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.73\nSaving best model in this fold: 0.7331\n\n---------- EPOCH: 4 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"778a2c702bf848598fdb51c7e78553aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6dda781331748449f778505a796af05"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.69\nSaving best model in this fold: 0.6920\n\n---------- EPOCH: 5 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c1153cf19b34046be548711c4a72fef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4726b0c08e744acbf7963450b9cfe69"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.67\nSaving best model in this fold: 0.6724\n\n---------- EPOCH: 6 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c883c6efccb34c8fbcdd1f921c219a19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"753c7f2df7654f5cbba65cd09d7d6048"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.66\nSaving best model in this fold: 0.6582\n\n---------- EPOCH: 7 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c6c0db6d9f04c84af2329987500048e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74501376b44f4740aebfcb2a961c84d7"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.65\nSaving best model in this fold: 0.6490\n\n---------- EPOCH: 8 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc2dd8b64e2490b98bbd544dcda20b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f9603506c8b4ac9a24694de1b152da6"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.66\n\n---------- EPOCH: 9 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf3dfc0f31164205a5fec16e76d8a3b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9d8cf4937324a84b3eb1e4d58381d67"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.66\n\n---------- EPOCH: 10 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a5b258fd67e41cfa108695e90d46f8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f19ce0ca53e74573acb0786edd54c036"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.66\nBest RMSE in fold: 2 was: 0.6490\nFinal RMSE in fold: 2 was: 0.6565\n\nFold: 3\n--------------------\n\n\n---------- EPOCH: 1 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65aecb058476409a9e6d6473073493e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27457c563ca8419f8b05f4eacc5fe471"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.90\nSaving best model in this fold: 0.8965\n\n---------- EPOCH: 2 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f29819fd9be54834a1e343c349d2e54e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5014977832c149bc8ae5a61cfb18b817"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.75\nSaving best model in this fold: 0.7534\n\n---------- EPOCH: 3 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b0ac6f5c59e4e499d779298e21e624e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4200a16fbeca4b07ac2a2da8f4724116"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.70\nSaving best model in this fold: 0.6971\n\n---------- EPOCH: 4 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fb9e3f11a00412aa16ea38a378ed378"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d828dd6bf1b4b42917c821bffcb9237"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.68\nSaving best model in this fold: 0.6850\n\n---------- EPOCH: 5 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6c77f25416a42a3b05b85311d3421a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8982f6f153154b68bdbed36485b44755"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.66\nSaving best model in this fold: 0.6617\n\n---------- EPOCH: 6 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7805066b18aa410789efd7b8241e89dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18d1b0613bd04ca7850f3fbb625fcf26"}},"metadata":{}},{"name":"stdout","text":"Validation RMSE: 0.66\nSaving best model in this fold: 0.6578\n\n---------- EPOCH: 7 ----------\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1dad2f19e940168359d80c0132a783"}},"metadata":{}}]},{"cell_type":"code","source":"plt.plot(train_losses)\nplt.title(\"Train\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(val_losses)\nplt.title(\"Val\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    MAX_LEN = 284\n    TRAIN_BS = 12\n    STATE_DIR = \"./states_list\"\n    MODEL_NAME = 'distilbert-base-uncased'\n    FILE_NAME = '../input/commonlitreadabilityprize/test.csv'\n    TOKENIZER = transformers.DistilBertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True)\n    scaler = GradScaler()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T11:20:14.600102Z","iopub.status.idle":"2022-09-16T11:20:14.600913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef inference(model, states_list, test_dataloader, device=torch.device('cuda:0')):\n    \"\"\"\n    Do inference for different model folds\n    \"\"\"\n    model.eval()\n    all_preds = []\n    for state in states_list:\n        print(f\"State: {state}\")\n        state_dict = torch.load(state)\n        model.load_state_dict(state_dict)\n        model = model.to(device)\n        \n        # Clean\n        del state_dict\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        preds = []\n        prog = tqdm(test_dataloader, total=len(test_dataloader))\n        for data in prog:\n            ids = data['ids'].to(DEVICE, dtype=torch.long)\n            mask = data['mask'].to(DEVICE, dtype=torch.long)\n\n            outputs = model(ids=ids, mask=mask)\n            preds.append(outputs.squeeze(-1).cpu().detach().numpy())\n            \n        all_preds.append(np.concatenate(preds))\n        \n        # Clean\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n    return all_preds","metadata":{"execution":{"iopub.status.busy":"2022-09-16T11:20:14.602182Z","iopub.status.idle":"2022-09-16T11:20:14.603031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inference Code\nif __name__ == '__main__':\n    if torch.cuda.is_available():\n        print(\"\\n[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n        DEVICE = torch.device('cuda:0')\n    else:\n        print(\"\\n[INFO] GPU not found. Using CPU: {}\\n\".format(platform.processor()))\n        DEVICE = torch.device('cpu')\n    \n    test_file = pd.read_csv(Config.FILE_NAME)\n    \n    test_data = BERTDataset(test_file['excerpt'].values, is_test=True)\n    test_data = DataLoader(\n        test_data,\n        batch_size=Config.TRAIN_BS,\n        shuffle=False\n    )\n    \n    state_list = [os.path.join(Config.STATE_DIR, x) for x in os.listdir(Config.STATE_DIR) if x.endswith(\".pt\")]\n    model = DBERT_BASE_UNCASED()\n    \n    print(\"Doing Predictions for all folds\")\n    predictions = inference(model, state_list, test_data, device=DEVICE)\n    \n    final_predictions = pd.DataFrame(predictions).T.mean(axis=1).tolist()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T11:20:14.604336Z","iopub.status.idle":"2022-09-16T11:20:14.605183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Form the sample submission\nsub = pd.DataFrame()\nsub['id'] = test_file['id']\nsub['target'] = final_predictions\n\nsub.to_csv(\"submission.csv\", index=None)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T11:20:14.606451Z","iopub.status.idle":"2022-09-16T11:20:14.607253Z"},"trusted":true},"execution_count":null,"outputs":[]}]}